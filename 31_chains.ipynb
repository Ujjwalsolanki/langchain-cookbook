{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939af86b",
   "metadata": {},
   "source": [
    "Chains in LangChain are like pipelines that **link different components together** to perform multi-step tasks with LLMs. Instead of making separate calls to a prompt, then an LLM, then a parser, chains allow you to define a sequence of operations where the output of one step becomes the input for the next. This simplifies your code, makes workflows clearer, and enhances reusability.\n",
    "\n",
    "-----\n",
    "\n",
    "## Simple Chain â›“ï¸\n",
    "\n",
    "A **Simple Chain** is the most basic form of chaining. It's a linear sequence where the output of one component directly feeds into the input of the next. Think of it as a straight line of operations.\n",
    "\n",
    "  * **Workflow**: Input â†’ Component A â†’ Component B â†’ Output\n",
    "  * **Example**: A common simple chain is `PromptTemplate | LLM | OutputParser`. The prompt formats the user input, the LLM generates a response, and the parser extracts the desired information.\n",
    "  * **Use Case**: Ideal for straightforward tasks that require a single, direct flow of execution, like generating a direct answer or a quick summary.\n",
    "\n",
    "-----\n",
    "\n",
    "## Sequential Chain âž¡ï¸âž¡ï¸\n",
    "\n",
    "A **Sequential Chain** is an extension of a simple chain, involving multiple steps where each step depends on the output of the previous one. While still linear, it handles more complex multi-phase tasks. The key here is that the output of one step is *explicitly* passed as input to the next.\n",
    "\n",
    "  * **Workflow**: Input â†’ Step 1 (Output 1) â†’ Step 2 (Output 2) â†’ Step 3 (Output 3) â†’ Final Output\n",
    "  * **Example**: Generating a detailed report, then summarizing that report. The full report from the first LLM call becomes the text to be summarized by the second LLM call.\n",
    "  * **Use Case**: When you have multi-stage processes where each stage builds upon the results of the preceding one, such as RAG (Retrieval-Augmented Generation) where you first retrieve documents, then use those documents to generate an answer.\n",
    "\n",
    "-----\n",
    "\n",
    "## Parallel Chain ðŸ‘¯\n",
    "\n",
    "A **Parallel Chain** allows you to execute multiple independent sub-chains or components **simultaneously** with the same initial input. The results from all parallel branches are then collected and combined into a single output (typically a dictionary).\n",
    "\n",
    "  * **Workflow**:\n",
    "    ```\n",
    "    Input\n",
    "      â”‚\n",
    "      â”œâ”€â”€â”€> Sub-chain A\n",
    "      â”‚\n",
    "      â”œâ”€â”€â”€> Sub-chain B\n",
    "      â”‚\n",
    "      â””â”€â”€â”€> Sub-chain C\n",
    "      â”‚\n",
    "    Combined Output (after all sub-chains complete)\n",
    "    ```\n",
    "  * **Example**: Given a document, simultaneously extract key themes, summarize it, and determine its sentiment. All three tasks operate on the *same initial document* but produce independent outputs.\n",
    "  * **Use Case**:\n",
    "      * **Speed Optimization**: Runs independent tasks concurrently, reducing overall execution time.\n",
    "      * **Independent Tasks**: When different pieces of information need to be extracted or processed from the same input, but their computations don't depend on each other.\n",
    "  * **Implementation**: Often achieved using `RunnableParallel` or a dictionary literal in LCEL (LangChain Expression Language).\n",
    "\n",
    "-----\n",
    "\n",
    "## Conditional Chain ðŸš¦\n",
    "\n",
    "A **Conditional Chain** introduces branching logic into your workflow. It allows you to dynamically choose which sub-chain or component to execute based on a specific condition derived from an intermediate output.\n",
    "\n",
    "  * **Workflow**:\n",
    "    ```\n",
    "    Input\n",
    "      â”‚\n",
    "      â”œâ”€â”€â”€> Initial Processing (e.g., Sentiment Analysis)\n",
    "      â”‚\n",
    "      â”œâ”€â”€â”€> Condition (e.g., Is sentiment positive?)\n",
    "      â”‚       â”œâ”€â”€â”€ IF TRUE â”€â”€â”€> Sub-chain A\n",
    "      â”‚       â””â”€â”€â”€ IF FALSE â”€â”€â”€> Sub-chain B\n",
    "      â”‚       â”œâ”€â”€â”€ Default â”€â”€â”€> default-chain \n",
    "      â”‚\n",
    "    Final Output\n",
    "    ```\n",
    "  * **Example**: Analyze user feedback. If the sentiment is positive, generate a \"thank you\" response. If negative, route it to a \"customer support\" chain.\n",
    "  * **Use Case**: For building dynamic and adaptive applications where the subsequent steps depend on the context or characteristics of the input or an intermediate result. This enables decision-making within the LLM workflow.\n",
    "  * **Implementation**: Typically implemented using `RunnableBranch` in LangChain, which takes a list of (condition, runnable) pairs and an optional default runnable. The `condition` is usually a Python function that inspects the intermediate state."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
