{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2026b5",
   "metadata": {},
   "source": [
    "## Why Do We Use Message Place holder?\n",
    "\n",
    "### Enabling Conversational Memory (Context)\n",
    "\n",
    "Large Language Models (LLMs) are inherently **stateless**; they don't \"remember\" past interactions unless you explicitly provide that context in each new prompt. `MessagesPlaceholder` allows you to **dynamically insert the entire history of a conversation** (previous user queries and AI responses) into the current prompt. This gives the AI the necessary context to understand ongoing dialogue, refer back to previous statements, and provide coherent, relevant replies.\n",
    "\n",
    "* **Example**: If a user asks \"What is LangChain?\" and then \"Tell me more about it,\" the \"it\" only makes sense if the AI remembers the previous turn was about LangChain. `MessagesPlaceholder` facilitates this.\n",
    "\n",
    "***\n",
    "\n",
    "### Structuring Complex Prompts\n",
    "\n",
    "It helps in building **structured prompts** where the system instructions, chat history, and the current query are clearly separated and ordered. This separation makes prompts easier to read, manage, and debug compared to concatenating long strings.\n",
    "\n",
    "***\n",
    "\n",
    "### Flexibility in History Management\n",
    "\n",
    "You can **pre-process or filter your `chat_history`** before passing it to the placeholder. For instance, you might only include the last N turns to manage token limits, or use a sophisticated memory system to retrieve relevant past interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d050d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# Import necessary message types (like HumanMessage, AIMessage) if you're building the history directly\n",
    "# from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c118297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ChatPromptTemplate.\n",
    "# This template structures the conversation for a chat model, specifying the roles\n",
    "# and content for different parts of the prompt.\n",
    "chat_template = ChatPromptTemplate([\n",
    "    # System Message: Establishes the AI's persona or overall instructions.\n",
    "    # In this case, it tells the AI to act as a helpful customer support agent.\n",
    "    ('system', 'You are a helpful customer support agent'),\n",
    "\n",
    "    # MessagesPlaceholder: This is the key component for managing conversation history.\n",
    "    # It acts as a placeholder that will be dynamically filled with a list of\n",
    "    # LangChain message objects (e.g., HumanMessage, AIMessage) representing\n",
    "    # previous turns in the conversation.\n",
    "    # 'variable_name' specifies the key in the 'invoke' dictionary that will hold\n",
    "    # the list of messages for this placeholder.\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "\n",
    "    # Human Message: This represents the current query from the user.\n",
    "    # '{query}' is a placeholder that will be filled with the current user's input.\n",
    "    ('human', '{query}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c550c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the chat history.\n",
    "# This list will hold the sequence of messages exchanged in the conversation.\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870b4410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HumanMessage(content=\"I want to request a refund for my order #12345.\")\\n', 'AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")']\n"
     ]
    }
   ],
   "source": [
    "# Load chat history from a text file.\n",
    "# This block attempts to read previous chat messages from 'chat_history.txt'.\n",
    "# Each line in the file is assumed to be a separate message or a part of the history.\n",
    "# Note: For a real application, you would typically parse these lines into\n",
    "# LangChain's HumanMessage and AIMessage objects to properly maintain context.\n",
    "# In this specific example, it just loads raw strings, which might not be\n",
    "# correctly interpreted by the LLM as distinct conversational turns without\n",
    "# further processing (e.g., converting them to HumanMessage/AIMessage instances).\n",
    "with open('data/16_chat_history.txt') as f:\n",
    "    chat_history.extend(f.readlines())\n",
    "\n",
    "# Print the raw loaded chat history (for debugging/inspection).\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5788e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final prompt by invoking the chat_template.\n",
    "# We pass a dictionary with:\n",
    "# - 'chat_history': The list of past messages (even if they are just strings in this example).\n",
    "#                  This will be inserted into the MessagesPlaceholder.\n",
    "# - 'query': The current user's question.\n",
    "prompt = chat_template.invoke({'chat_history':chat_history, 'query':'Where is my refund'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful customer support agent', additional_kwargs={}, response_metadata={}), HumanMessage(content='HumanMessage(content=\"I want to request a refund for my order #12345.\")\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")', additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is my refund', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Print the resulting prompt object.\n",
    "# This will show the combined system message, the inserted chat history (as string content),\n",
    "# and the current human query, ready to be sent to a chat model.\n",
    "# now llm will understand the context of the conversation.\n",
    "# Note: The actual content of the prompt will depend on how the chat history is formatted\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
