{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f366c1e2",
   "metadata": {},
   "source": [
    "## This code will not work until you run 10_prompt_generator_ipynb file\n",
    "\n",
    "### Or you can create your own prompt in json file and add that json file in the artifacts folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758d0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, load_prompt\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637c41e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "# This is crucial for ChatOpenAI to pick up your OpenAI API key.\n",
    "# Make sure your .env file contains: OPENAI_API_KEY=\"your_api_key_here\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8506a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI model.\n",
    "# By default, it will use the API key loaded from the environment variable.\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537431cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research paper selection\n",
    "paper_input = \"Attention Is All You Need\"\n",
    "# You can change this to any of the options:\n",
    "# \"Attention Is All You Need\"\n",
    "# \"BERT: Pre-training of Deep Bidirectional Transformers\"\n",
    "# \"GPT-3: Language Models are Few-Shot Learners\"\n",
    "# \"Diffusion Models Beat GANs on Image Synthesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83cb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation style selection\n",
    "style_input = \"Beginner-Friendly\"\n",
    "# You can change this to any of the options:\n",
    "# \"Beginner-Friendly\"\n",
    "# \"Technical\"\n",
    "# \"Code-Oriented\"\n",
    "# \"Mathematical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c91a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation length selection\n",
    "length_input = \"Medium (3-5 paragraphs)\"\n",
    "# You can change this to any of the options:\n",
    "# \"Short (1-2 paragraphs)\"\n",
    "# \"Medium (3-5 paragraphs)\"\n",
    "# \"Long (detailed explanation)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f02a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template 'template.json' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load the prompt template ---\n",
    "# IMPORTANT: Ensure you have a file named 'template.json' in the same directory\n",
    "# as your Jupyter Notebook, containing your prompt template definition.\n",
    "# Example template.json content:\n",
    "# {\n",
    "#   \"_type\": \"prompt\",\n",
    "#   \"input_variables\": [\"paper_input\", \"style_input\", \"length_input\"],\n",
    "#   \"template\": \"Explain the research paper '{paper_input}' in a {style_input} style, with a {length_input} explanation.\"\n",
    "# }\n",
    "try:\n",
    "    template = load_prompt('artifacts/prompt_template.json')\n",
    "    print(\"Prompt template 'template.json' loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'template.json' not found. Please create this file with your prompt template.\")\n",
    "    print(\"Example content for template.json:\")\n",
    "    print(\"\"\"\n",
    "            {\n",
    "            \"_type\": \"prompt\",\n",
    "            \"input_variables\": [\"paper_input\", \"style_input\", \"length_input\"],\n",
    "            \"template\": \"Explain the research paper '{paper_input}' in a {style_input} style, with a {length_input} explanation.\"\n",
    "            }\n",
    "    \"\"\")\n",
    "    exit() # Exit if the template file is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566f658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LangChain chain: PromptTemplate -> ChatOpenAI model\n",
    "# Don't get confused by the name 'chain' here; it's just a term used in LangChain to represent a sequence of operations.\n",
    "# The 'template' is the prompt template, and 'model' is the ChatOpenAI model.\n",
    "# I will explain more about chains in the next chapter.\n",
    "chain = template | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286bdda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating explanation for: 'Attention Is All You Need'\n",
      "Style: 'Beginner-Friendly', Length: 'Medium (3-5 paragraphs)'\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with the selected inputs\n",
    "print(f\"\\nGenerating explanation for: '{paper_input}'\")\n",
    "print(f\"Style: '{style_input}', Length: '{length_input}'\")\n",
    "\n",
    "result = chain.invoke({\n",
    "    'paper_input': paper_input,\n",
    "    'style_input': style_input,\n",
    "    'length_input': length_input\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad71e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Explanation ---\n",
      "The research paper \"Attention Is All You Need\" introduces a new neural network architecture called the Transformer, which is designed for natural language processing tasks. Unlike traditional sequence-to-sequence models that rely on recurrent neural networks (RNNs) or convolutional neural networks (CNNs), the Transformer relies solely on the mechanism of attention. This attention mechanism allows the model to focus on different parts of the input sequence when generating the output sequence, making it more efficient and effective for tasks like translation and text generation.\n",
      "\n",
      "Mathematically, the core idea behind the Transformer is the concept of self-attention, where each word in the input sequence can attend to every other word in the sequence to determine its relevance. This is achieved through three key components: the query, key, and value matrices. These matrices are used to calculate the attention scores between words in the input sequence, which are then used to weigh the corresponding values to produce the output representation for each word.\n",
      "\n",
      "An analogy to explain self-attention is to imagine a classroom where each student (word) has a set of friends (other words) they want to pay attention to. The student can calculate how important each friend is based on factors like similarity or relevance (query and key matrices) and then combine the information from all friends to create a comprehensive understanding (value matrix).\n",
      "\n",
      "By using self-attention mechanisms in the Transformer architecture, the model can effectively capture long-range dependencies in the input sequence and generate more coherent and accurate outputs. The paper demonstrates that the Transformer outperforms traditional models on various language tasks such as machine translation and language modeling, showcasing the power of attention-based models in natural language processing.\n"
     ]
    }
   ],
   "source": [
    "# Print the generated content directly to the notebook output\n",
    "print(\"\\n--- Generated Explanation ---\")\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
