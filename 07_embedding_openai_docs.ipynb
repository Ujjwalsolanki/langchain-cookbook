{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e84cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04623187333345413, -0.03608284145593643, 0.08614983409643173, 0.19587160646915436, -0.01688387058675289, -0.08273564279079437, -0.26228460669517517, 0.27294811606407166, 0.15611733496189117, -0.36012688279151917, 0.1310487687587738, 0.25274360179901123, 0.030470475554466248, -0.07024812698364258, -0.1956845223903656, -0.06631946563720703, -0.3105509579181671, 0.1813729852437973, 0.32383355498313904, -0.07913437485694885, 0.05944431945681572, -0.18661120533943176, -0.02384086698293686, 0.12945859134197235, 0.26060089468955994, 0.2607879936695099, 0.022648239508271217, 0.1583622843027115, 0.1851145625114441, 0.07735712081193924, -0.031078482046723366, -0.1333872526884079], [-0.1305832415819168, 0.022755296900868416, 0.14982350170612335, -0.09551817178726196, -0.12261391431093216, -0.002385463798418641, -0.38639891147613525, 0.10411366820335388, 0.15471895039081573, -0.42738404870033264, -0.08720729500055313, 0.25160327553749084, -0.23384305834770203, 0.01739022694528103, 0.025886107236146927, -0.05077604949474335, -0.42442402243614197, 0.23076917231082916, -0.03270273655653, 0.03201964870095253, 0.09654279798269272, 0.025402255356311798, -0.061193108558654785, 0.0946643128991127, 0.1510758250951767, 0.10434136539697647, -0.17475612461566925, 0.2027626484632492, 0.09511970728635788, 0.11623844504356384, 0.06910552084445953, -0.22154751420021057], [0.07097373902797699, 0.2438550591468811, 0.1314353346824646, -0.006076289340853691, -0.2119838297367096, 0.1573474407196045, -0.11777622997760773, 0.4314667582511902, 0.016898110508918762, -0.05667855590581894, -0.0932702049612999, 0.11436145752668381, 0.07298243045806885, 0.011491385288536549, -0.14194747805595398, -0.039604686200618744, -0.3213905096054077, 0.24398896098136902, 0.0856371819972992, 0.0669228807091713, 0.2643437087535858, -0.20890383422374725, -0.011918231844902039, 0.305053174495697, 0.25818371772766113, 0.16230221092700958, -0.009968128055334091, -0.28496626019477844, -0.034884262830019, -0.03357861191034317, 0.14127790927886963, -0.13431444764137268]]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file.\n",
    "# This best practice ensures that sensitive information like API keys is\n",
    "# not hardcoded directly into your script, promoting security and flexibility.\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAIEmbeddings model.\n",
    "# This component is responsible for converting text into high-dimensional\n",
    "# numerical vectors, capturing their semantic meaning.\n",
    "# - 'model': Specifies the particular OpenAI embedding model to use.\n",
    "#            'text-embedding-3-small' is a state-of-the-art model offering\n",
    "#            robust performance for various tasks.\n",
    "# - 'dimensions': Sets the desired dimensionality of the output embedding vectors.\n",
    "#                 Here, each piece of text will be represented by a 32-dimensional vector.\n",
    "#                 This can be useful for managing computational resources or storage,\n",
    "#                 as larger dimensions generally mean more detail but also more data.\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=32)\n",
    "\n",
    "# Define a list of documents (strings) to be embedded.\n",
    "# Each string in this list represents a separate document for which we want\n",
    "# to generate an embedding.\n",
    "documents = [\n",
    "    \"Tokyo is the capital of Japan\",\n",
    "    \"Rome is the capital of Italy\",\n",
    "    \"Berlin is the capital of Germany\"\n",
    "]\n",
    "\n",
    "# Embed multiple documents simultaneously.\n",
    "# The 'embed_documents' method takes a list of strings and returns a list\n",
    "# of embedding vectors, where each vector corresponds to a document in the input list.\n",
    "# This is more efficient than embedding each document individually when dealing with batches.\n",
    "result = embedding.embed_documents(documents)\n",
    "\n",
    "# Print the list of resulting embedding vectors.\n",
    "# The 'result' will be a list of lists of floats, where each inner list is\n",
    "# the embedding vector for a corresponding document from the 'documents' list.\n",
    "print(str(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
