{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeb554d",
   "metadata": {},
   "source": [
    "## How to Generate and Save a Prompt in a JSON File\n",
    "\n",
    "The code above demonstrates a robust way to define a **`PromptTemplate`** in LangChain and then **save** it to a JSON file. This is incredibly useful for several reasons:\n",
    "\n",
    "* **Reusability:** Once defined and saved, you can load this template in other parts of your application or even different projects, avoiding redundant code.\n",
    "* **Version Control:** Prompt templates can be managed under version control (e.g., Git) just like any other code or configuration file.\n",
    "* **Separation of Concerns:** It separates the prompt definition from your application logic, making your code cleaner and more modular.\n",
    "* **Easy Sharing:** You can easily share your well-crafted prompts with teammates or collaborators.\n",
    "\n",
    "### Step-by-Step Breakdown:\n",
    "\n",
    "1.  **Define the `PromptTemplate`:** You create an instance of `PromptTemplate`, providing the actual template string (with placeholders) and specifying the `input_variables`. The `validate_template=True` ensures your placeholders match your input variables.\n",
    "2.  **Save to JSON:** The magical part is `template.save('template.json')`. This method handles the serialization. LangChain internally converts the `PromptTemplate` object into a JSON format that captures all its essential components.\n",
    "\n",
    "### What does `template.json` look like?\n",
    "\n",
    "If you open the `template.json` file generated by this script, you'd typically see something like this (exact format might vary slightly with LangChain versions):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"lc_kwargs\": {\n",
    "    \"input_variables\": [\n",
    "      \"paper_input\",\n",
    "      \"style_input\",\n",
    "      \"length_input\"\n",
    "    ],\n",
    "    \"template\": \"\\nPlease summarize the research paper titled \\\"{paper_input}\\\" with the following specifications:\\nExplanation Style: {style_input}  \\nExplanation Length: {length_input}  \\n1. Mathematical Details:  \\n    - Include relevant mathematical equations if present in the paper.  \\n    - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \\n2. Analogies:  \\n    - Use relatable analogies to simplify complex ideas.  \\nIf certain information is not available in the paper, respond with: \\\"Insufficient information available\\\" instead of guessing.  \\nEnsure the summary is clear, accurate, and aligned with the provided style and length.\\n\"\n",
    "  },\n",
    "  \"lc_namespace\": [\n",
    "    \"langchain_core\",\n",
    "    \"prompts\",\n",
    "    \"prompt\"\n",
    "  ],\n",
    "  \"lc_obj_type\": \"PromptTemplate\",\n",
    "  \"lc_version\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e76a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "import json # Import the json module to work with JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a PromptTemplate.\n",
    "# A PromptTemplate is a powerful LangChain component that allows you to create\n",
    "# flexible and reusable templates for generating prompts for language models.\n",
    "# It defines a structured string with placeholders that can be filled dynamically.\n",
    "#\n",
    "# - 'template': This is the core string of the prompt. It contains placeholders\n",
    "#               enclosed in curly braces (e.g., \"{paper_input}\"). These placeholders\n",
    "#               will be replaced with actual values when the template is used.\n",
    "#               This specific template is designed to instruct an LLM to summarize\n",
    "#               a research paper with detailed specifications regarding style, length,\n",
    "#               inclusion of mathematical details (with code snippets), and analogies.\n",
    "# - 'input_variables': This is a list of strings that explicitly declares the names\n",
    "#                      of the placeholders used in the 'template'. LangChain uses\n",
    "#                      this to validate that all expected variables are provided\n",
    "#                      when the template is invoked.\n",
    "# - 'validate_template': When set to True, LangChain will perform a check to ensure\n",
    "#                        that all variables declared in 'input_variables' are actually\n",
    "#                        present in the 'template' string, helping to catch typos or\n",
    "#                        missing placeholders early.\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "            Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "            Explanation Style: {style_input}  \n",
    "            Explanation Length: {length_input}  \n",
    "            1. Mathematical Details:  \n",
    "                - Include relevant mathematical equations if present in the paper.  \n",
    "                - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \n",
    "            2. Analogies:  \n",
    "                - Use relatable analogies to simplify complex ideas.  \n",
    "            If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.  \n",
    "            Ensure the summary is clear, accurate, and aligned with the provided style and length.\n",
    "        \"\"\",\n",
    "    input_variables=['paper_input', 'style_input', 'length_input'],\n",
    "    validate_template=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facd508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PromptTemplate has been successfully saved to 'prompt_template.json'.\n"
     ]
    }
   ],
   "source": [
    "# Save the PromptTemplate to a JSON file.\n",
    "# The 'save()' method of PromptTemplate serializes the template's structure,\n",
    "# including its template string and input variables, into a JSON format.\n",
    "# This allows for easy persistence, sharing, and loading of prompt templates\n",
    "# across different applications or sessions without needing to redefine them in code.\n",
    "# The file 'template.json' will contain the serialized representation.\n",
    "template.save('artifacts/prompt_template.json')\n",
    "\n",
    "print(\"PromptTemplate has been successfully saved to 'prompt_template.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
