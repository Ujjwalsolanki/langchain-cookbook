{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67383b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker # Imports the semantic chunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings # Imports OpenAI's embedding model\n",
    "from dotenv import load_dotenv # For loading environment variables\n",
    "\n",
    "# Load environment variables from a .env file. üåç\n",
    "# This is crucial for securely loading your API keys (e.g., OPENAI_API_KEY),\n",
    "# which are required for OpenAIEmbeddings.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882e7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SemanticChunker. ‚úÇÔ∏è\n",
    "# This splitter is different from character-based splitters because it uses\n",
    "# embeddings to understand the meaning of the text.\n",
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), # The embedding model used to convert text into numerical vectors.\n",
    "                        # SemanticChunker calculates embeddings for sentences/paragraphs\n",
    "                        # to measure their semantic similarity.\n",
    "    breakpoint_threshold_type=\"standard_deviation\", # Determines how break points are identified.\n",
    "                                                    # \"standard_deviation\" means it looks for\n",
    "                                                    # points where the cosine similarity between\n",
    "                                                    # consecutive sentences deviates significantly\n",
    "                                                    # from the average.\n",
    "    breakpoint_threshold_amount=3 # The multiplier for the standard deviation. A higher value\n",
    "                                  # means it will be less sensitive to minor changes and\n",
    "                                  # create larger, fewer chunks. A lower value (e.g., 1)\n",
    "                                  # would create more, smaller chunks, being more sensitive\n",
    "                                  # to subtle semantic shifts.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ad6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample text to be split. üìÑ\n",
    "# This text contains distinct topics: farming, cricket (IPL), and terrorism.\n",
    "# The expectation is that SemanticChunker will identify these topic shifts.\n",
    "sample = \"\"\"\n",
    "Farmers were working hard in the fields, preparing the soil and planting seeds for the next season. The sun was bright, and the air smelled of earth and fresh grass. The Indian Premier League (IPL) is the biggest cricket league in the world. People all over the world watch the matches and cheer for their favourite teams.\n",
    "Terrorism is a big danger to peace and safety. It causes harm to people and creates fear in cities and villages. When such attacks happen, they leave behind pain and sadness. To fight terrorism, we need strong laws, alert security forces, and support from people who care about peace and safety.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91efcc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents (chunks) from the sample text. üìù\n",
    "# The `create_documents` method processes the input text, calculates embeddings,\n",
    "# identifies semantic breakpoints based on the configured threshold, and returns\n",
    "# a list of `Document` objects, where each document is a semantically coherent chunk.\n",
    "docs = text_splitter.create_documents([sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8cb1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the number of chunks created. üìè\n",
    "# This will show how many distinct semantic segments the text was broken into.\n",
    "print(f\"Number of chunks: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354dc4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Chunks:\n",
      "--- Chunk 1 ---\n",
      "\n",
      "Farmers were working hard in the fields, preparing the soil and planting seeds for the next season. The sun was bright, and the air smelled of earth and fresh grass. The Indian Premier League (IPL) is the biggest cricket league in the world. People all over the world watch the matches and cheer for their favourite teams. Terrorism is a big danger to peace and safety. It causes harm to people and creates fear in cities and villages. When such attacks happen, they leave behind pain and sadness. To fight terrorism, we need strong laws, alert security forces, and support from people who care about peace and safety. \n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the content of each generated chunk. üìä\n",
    "# You'll notice that the chunks ideally separate the different topics present in the `sample` text.\n",
    "print(\"Generated Chunks:\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
